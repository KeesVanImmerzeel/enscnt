txt <- text %>%
sampleNlines(aFraction = 0.01, maxNrLines = 5000)  %>%
ngram(n) %>%
get.phrasetable ()
return(text)
}
generateTableOfngrams(xs, n=1)
xs
generateTableOfngrams <- function(text, n) {
txt <- text %>%
ngram(n) %>%
get.phrasetable ()
return(text)
}
generateTableOfngrams(xs, n=1)
ngram1 <- generateTableOfngrams(xs, n=1)
ngram1
ngram(xs)
ngram(xs) %>% get.phrasetable()
generateTableOfngrams <- function(text, n) {
txt <- text %>%
ngram(n) %>%
get.phrasetable()
return(txt)
}
ngram1 <- generateTableOfngrams(xs, n=1)
ngram1
x <- ensentences
xs <- sampleNlines(text=x, aFraction = 0.01, maxNrLines = 1000)
x[1000]
?sample
sampleNlines <- function ( text, aFraction ){
nrLines <- length(text)
i <- rbinom(n = nrLines,
size = 1,
prob = aFraction)
return(sentences[i == 1])
}
xs <- sampleNlines(text=x, aFraction = 0.01)
xs
length(xs)
generateTableOfngrams <- function(text, n) {
txt <- text %>%
ngram(n) %>%
get.phrasetable()
return(txt)
}
ngram1 <- generateTableOfngrams(xs, n=1)
xs <- sampleNlines(text=x, aFraction = 0.01)
xs
xs %>% ngram(1)
xs
xs %>% ngram(1)
xs <- xs[1:10]
xs %>% ngram(1)
xs <- sampleNlines(text=x, aFraction = 0.01)
xs <- stri_remove_empty(xs)
ngram1 <- generateTableOfngrams(xs, n=1)
ngram1
?trimws()
?tolower()
?stri_remove_empty
library(devtools)
use_package(stringi)
use_package("stringi")
clean_text <- function(x) {
text <- x %>%
textclean::replace_word_elongation() %>% # Replace elongation words
gsub("[^A-Za-z ]", "", .) %>% # Remove all characters that are not letters or space.
gsub("\\s+", " ", .) %>% # Remove multiple white spaces
trimws() %>% # Trim trailing and leading white space
tolower() %>%  # Convert to lowercase
stri_remove_empty()
return(text)
}
library (devtools)
library (ngram)
library(magrittr)
library(stringi)
library(enscnt)
setwd("~/kees/Coursera/DataScience/Capstone2")
sampleNlines <- function ( text, aFraction ){
nrLines <- length(text)
i <- rbinom(n = nrLines,
size = 1,
prob = aFraction)
return(sentences[i == 1])
}
generateTableOfngrams <- function(text, n) {
txt <- text %>%
ngram(n) %>%
get.phrasetable()
return(txt)
}
x <- ensentences
xs <- sampleNlines(text=x, aFraction = 0.01)
ngram1 <- generateTableOfngrams(xs, n=1)
library(devtools)
devtools::install_github("KeesVanImmerzeel/ensnct")
devtools::install_github("KeesVanImmerzeel/enscnt")
library(enscnt)
x <- ensentences
xs <- sampleNlines(text=x, aFraction = 0.01)
sampleNlines <- function ( text, aFraction ){
nrLines <- length(text)
i <- rbinom(n = nrLines,
size = 1,
prob = aFraction)
return(sentences[i == 1])
}
generateTableOfngrams <- function(text, n) {
txt <- text %>%
ngram(n) %>%
get.phrasetable()
return(txt)
}
xs <- sampleNlines(text=x, aFraction = 0.01)
ngram1 <- generateTableOfngrams(xs, n=1)
library (devtools)
library (ngram)
library(magrittr)
library(stringi)
library(enscnt)
ngram1 <- generateTableOfngrams(xs, n=1)
library(enscnt)
?enscnt
clean_text()
??clean_text()
devtools::install_github("KeesVanImmerzeel/ensnct")
devtools::install_github("KeesVanImmerzeel/enscnt")
library(enscnt)
xs <- sampleNlines(text=x, aFraction = 0.01)
library (devtools)
library (ngram)
library(magrittr)
library(stringi)
library(enscnt)
setwd("~/kees/Coursera/DataScience/Capstone2")
sampleNlines <- function ( text, aFraction ){
nrLines <- length(text)
i <- rbinom(n = nrLines,
size = 1,
prob = aFraction)
return(sentences[i == 1])
}
generateTableOfngrams <- function(text, n) {
txt <- text %>%
ngram(n) %>%
get.phrasetable()
return(txt)
}
xs <- sampleNlines(text=x, aFraction = 0.01)
x <- ensentences
xs <- sampleNlines(text=x, aFraction = 0.01)
ngram1 <- generateTableOfngrams(xs, n=1)
methods(clean_text)
clean_text
?stri_remove_empty
i <- which(xs=="")
i
xs[6609]
clean_text <- function(x) {
text <- x %>%
textclean::replace_word_elongation() %>% # Replace elongation words
gsub("[^A-Za-z ]", "", .) %>% # Remove all characters that are not letters or space.
gsub("\\s+", " ", .) %>% # Remove multiple white spaces
trimws() %>% # Trim trailing and leading white space
tolower() %>%  # Convert to lowercase
stringi::stri_remove_empty() # Remove empty lines
return(text)
}
library(magrittr)
library(enscnt)
## Prepare cleaned dataset `sentences`
ensentences <- readLines("data-raw/en.txt", warn = FALSE) %>% clean_text(.)
which(ensentences=="")
usethis::use_data(ensentences, overwrite = TRUE)
devtools::install_github("KeesVanImmerzeel/enscnt")
library(devtools)
devtools::install_github("KeesVanImmerzeel/enscnt")
libPaths()
.libPaths
.libPaths()
library(devtools)
library(devtools)
devtools::install_github("KeesVanImmerzeel/enscnt")
devtools::install_github("KeesVanImmerzeel/enscnt",force=TRUE)
library(stringi)
?stri_remove_empty()
#' Transform text with non-text characters to 'clean' text
#'
#' Remove non-text characters. Numbers are also removed.
#'
#' @param x (character) Text to clean.
#'
#' @return (character) Cleaned text.
#'
#' @importFrom textclean replace_word_elongation
#' @importFrom magrittr %>%
#' @importFrom stringi stri_remove_empty
#'
#' @export
clean_text <- function(x) {
text <- x %>%
textclean::replace_word_elongation() %>% # Replace elongation words
gsub("[^A-Za-z ]", "", .) %>% # Remove all characters that are not letters or space.
gsub("\\s+", " ", .) %>% # Remove multiple white spaces
trimws() %>% # Trim trailing and leading white space
tolower() %>%  # Convert to lowercase
stringi::stri_remove_empty_na() # Remove empty lines
return(text)
}
library(magrittr)
library(enscnt)
clean_text <- function(x) {
text <- x %>%
textclean::replace_word_elongation() %>% # Replace elongation words
gsub("[^A-Za-z ]", "", .) %>% # Remove all characters that are not letters or space.
gsub("\\s+", " ", .) %>% # Remove multiple white spaces
trimws() %>% # Trim trailing and leading white space
tolower() %>%  # Convert to lowercase
stringi::stri_remove_empty_na() # Remove empty lines
return(text)
}
## Prepare cleaned dataset `sentences`
ensentences <- readLines("data-raw/en.txt", warn = FALSE) %>% clean_text(.)
i <- is.na(ensentences)
range(i)
i <- ensentences==""
range(i)
usethis::use_data(ensentences, overwrite = TRUE)
.libPaths
.libPaths()
library(devtools)
document()
load_all()
?sampleNlines()
?word_count()
load_all()
library(enscnt)
?word_count()
?generateTableOfngrams
?enscnt
library(devtools)
devtools::load_all()
?enscnt
library(devtools)
document()
document()
document()
load_all()
x <- ensentences
xs <- sampleNlines(x, 0.01)
ngram2 <- generateTableOfngrams(xs, n=2)
library(devtools)
load_all()
document()
load_al()
load_all()
?enscnt
?count_words
?word_count
devtools::use_package(stats)
library(devtools)
use_package(stats)
library(stats)
use_package(stats)
use_package("stats")
load_all()
x <- ensentences
xs <- sampleNlines(x, 0.01)
ngram1 <- generateTableOfngrams(xs, n=1)
xs[1]
text <- xs
n <- 1
test <- text[i == TRUE]
i <- (word_count(text) >= n)
test <- text[i == TRUE]
tmp <- test %>% ngram::ngram(n) %>%
get.phrasetable()
document()
document()
document()
load_all()
x <- ensentences
xs <- sampleNlines(x, 0.01)ngram1 <- generateTableOfngrams(xs, n=1)
x <- ensentences
xs <- sampleNlines(x, 0.01)
ngram1 <- generateTableOfngrams(xs, n=1)
ngram2 <- generateTableOfngrams(xs, n=2)
xs
text <- xs
n <- 2
text <- text[i == TRUE]
ngram_table <- text %>% ngram::ngram(n) %>%
ngram::get.phrasetable()
str(text)
str(xs)
xs[1]
xs[2]
i <- word_count(xs)
range(i)
which(i==0)
xs[8286]
x <- xs
text <- x %>%
textclean::replace_word_elongation() %>% # Replace elongation words
gsub("[^A-Za-z ]", "", .) %>% # Remove all characters that are not letters or space.
gsub("\\s+", " ", .) %>% # Remove multiple white spaces
trimws() %>% # Trim trailing and leading white space
tolower() %>%  # Convert to lowercase
stringi::stri_remove_empty_na() # Remove empty lines
which(is.na(text))
library(magrittr)
library(enscnt)
## Prepare cleaned dataset `sentences`
ensentences <- readLines("data-raw/en.txt", warn = FALSE) %>% clean_text(.)
usethis::use_data(ensentences, overwrite = TRUE)
which(is.na(ensentences))
load_all()
x <- ensentences
xs <- sampleNlines(x, 0.01)
which(is.na(xs))
ngram1 <- generateTableOfngrams(xs, n=1)
ngram2 <- generateTableOfngrams(xs, n=2)
which(is.na(xs))
text <- xs
i <- sapply(text, stringi::stri_stats_latex, USE.NAMES = FALSE)
which(is.na(i))
range(i)
length(i)
which(i==0)
?stri_stats_latex
test <- stri_stats_latex(xs)
str(test)
test["Words",]
test["Words",]
test[,"Words"]
head(test)
test$Words
load_all()
load_all()
xs
x <- xs
text <- xs
test <- word_count(text)
range(test)
load_all()
x <- ensentences
xs <- sampleNlines(x, 0.01)
ngram1 <- generateTableOfngrams(xs, n=1)
ngram2 <- generateTableOfngrams(xs, n=2)
plot_ngrams(ngram2, title="", n=2, m=5)
document()
str(ngram1)
document()
document()
load_all()
?enscnt
?enscnt
document()
?enscnt
load_all()
?clean_text
?word_count
?ngrams_table
?nsampeNlines
?sampleNlines
?plot_ngrams
library(enscnt)
devtools::install_github("KeesVanImmerzeel/enscnt")
library(devtools)
devtools::install_github("KeesVanImmerzeel/enscnt")
library(enscnt)
?enscnt
library(devtools)
use_package("ngram")
use_package("graphics")
word_count("This sentence has four words")
str(word_count("This sentence has four words"))
x <- word_count("This sentence has four words")
str(x)
name(x)
names(x)
namex(x) <- NULL
names(x) <- NULL
str(x)
word_count <- function(text) {
i <- sapply(text, stringi::stri_stats_latex, USE.NAMES = FALSE)
res <- i["Words", ]
names(res) <- NULL
return(res)
}
word_count("This sentence has four words")
document()
?ensentences
ensentences[1]
write_randomly_selected_lines <- function(text, filename, perc=.25) {
i <- rbinom(n = length(text),
size = 1,
perc = .25)
text <- text[i == 1]
con <- file(filename, open="wt")
writeLines(txt, con)
close(con)
}
tw <- readLines("data-raw/en_US.twitter.txt", warn = FALSE)
bl <-  readLines("data-raw/en_US.blogs.txt", warn = FALSE)
ne <- readLines("data-raw/en_US.news.txt", warn = FALSE)
# Create file "data-raw/en.txt" (use 25% of the original lines)
sentences <- append(tw,bl) %>% append(.,ne) %>% write_randomly_selected_lines("data-raw/en.txt", .25 )
library(magrittr)
# Create file "data-raw/en.txt" (use 25% of the original lines)
sentences <- append(tw,bl) %>% append(.,ne) %>% write_randomly_selected_lines("data-raw/en.txt", .25 )
?rbinom
write_randomly_selected_lines <- function(text, filename, perc=.25) {
i <- rbinom(n = length(text),
size = 1,
perc = perc)
text <- text[i == 1]
con <- file(filename, open="wt")
writeLines(txt, con)
close(con)
}
# Create file "data-raw/en.txt" (use 25% of the original lines)
sentences <- append(tw,bl) %>% append(.,ne) %>% write_randomly_selected_lines("data-raw/en.txt", .25 )
write_randomly_selected_lines <- function(text, filename, perc=.25) {
i <- rbinom(n = length(text),
size = 1,
prob = perc)
text <- text[i == 1]
con <- file(filename, open="wt")
writeLines(txt, con)
close(con)
}
# Create file "data-raw/en.txt" (use 25% of the original lines)
sentences <- append(tw,bl) %>% append(.,ne) %>% write_randomly_selected_lines("data-raw/en.txt", .25 )
write_randomly_selected_lines <- function(text, filename, perc=.25) {
i <- rbinom(n = length(text),
size = 1,
prob = perc)
text <- text[i == 1]
con <- file(filename, open="wt")
writeLines(text, con)
close(con)
}
# Create file "data-raw/en.txt" (use 25% of the original lines)
sentences <- append(tw,bl) %>% append(.,ne) %>% write_randomly_selected_lines("data-raw/en.txt", .25 )
# Create file "data-raw/en.txt" (use 25% of the original lines)
append(tw,bl) %>% append(.,ne) %>% write_randomly_selected_lines("data-raw/en.txt", .25 )
tw <- readLines("data-raw/en_US.twitter.txt", warn = FALSE)
bl <-  readLines("data-raw/en_US.blogs.txt", warn = FALSE)
ne <- readLines("data-raw/en_US.news.txt", warn = FALSE)
# Create file "data-raw/en.txt" (use 25% of the original lines)
append(tw,bl) %>% append(.,ne) %>% write_randomly_selected_lines("data-raw/en.txt", .25 )
tw %>% write_randomly_selected_lines("data-raw/en_tw.txt", .5 )
bl %>% write_randomly_selected_lines("data-raw/en_bl.txt", .5 )
bl %>% write_randomly_selected_lines("data-raw/en_bl.txt", .4 )
np %>% write_randomly_selected_lines("data-raw/en_np.txt", .5 )
ne %>% write_randomly_selected_lines("data-raw/en_ne.txt", .5 )
ne <- readLines("data-raw/en_US.news.txt", warn = FALSE)
ne %>% write_randomly_selected_lines("data-raw/en_ne.txt", .5 )
ne <- readLines("data-raw/en_US.news.txt", warn = FALSE)
ne %>% write_randomly_selected_lines("data-raw/en_ne.txt", 1 )
library(devtools)
document()
library(magrittr)
library(enscnt)
## Prepare cleaned dataset `sentences`
ensentences <- readLines("data-raw/en_bl.txt", warn = FALSE) %>% clean_text(.)
usethis::use_data(en_bl, overwrite = TRUE)
en_bl <- readLines("data-raw/en_bl.txt", warn = FALSE) %>% clean_text(.)
usethis::use_data(en_bl, overwrite = TRUE)
library(magrittr)
library(enscnt)
## Prepare cleaned dataset `sentences`
en_ne <- readLines("data-raw/en_ne.txt", warn = FALSE) %>% clean_text(.)
usethis::use_data(en_ne, overwrite = TRUE)
library(magrittr)
library(enscnt)
## Prepare cleaned dataset `sentences`
en_tw <- readLines("data-raw/en_tw.txt", warn = FALSE) %>% clean_text(.)
usethis::use_data(en_tw, overwrite = TRUE)
write_randomly_selected_lines <- function(text, filename, perc = .25) {
i <- rbinom(n = length(text),
size = 1,
prob = perc)
text <- text[i == 1]
con <- file(filename, open = "wt")
writeLines(text, con)
close(con)
}
# Read source files.
tw <- readLines("data-raw/en_US.twitter.txt", warn = FALSE)
bl <-  readLines("data-raw/en_US.blogs.txt", warn = FALSE)
ne <- readLines("data-raw/en_US.news.txt", warn = FALSE)
# Create output files
append(tw, bl) %>% append(., ne) %>% write_randomly_selected_lines("data-raw/en.txt", .25)
library(magrittr)
library(enscnt)
## Prepare cleaned dataset `sentences`
ensentences <- readLines("data-raw/en.txt", warn = FALSE) %>% clean_text(.)
usethis::use_data(ensentences, overwrite = TRUE)
?enscnt
library(enscnt)
?enscnt
en_tw_sentences[1]
en_tw_sentences[2]
?ensentences
ensentences[1]
ensentences[2]
ensentences[3]
