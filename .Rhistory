word_count <- function(text) {
i <- sapply(text, stringi::stri_stats_latex, USE.NAMES = FALSE)
res <- i["Words", ]
names(res) <- NULL
return(res)
}
word_count("This sentence has four words")
document()
?ensentences
ensentences[1]
write_randomly_selected_lines <- function(text, filename, perc=.25) {
i <- rbinom(n = length(text),
size = 1,
perc = .25)
text <- text[i == 1]
con <- file(filename, open="wt")
writeLines(txt, con)
close(con)
}
tw <- readLines("data-raw/en_US.twitter.txt", warn = FALSE)
bl <-  readLines("data-raw/en_US.blogs.txt", warn = FALSE)
ne <- readLines("data-raw/en_US.news.txt", warn = FALSE)
# Create file "data-raw/en.txt" (use 25% of the original lines)
sentences <- append(tw,bl) %>% append(.,ne) %>% write_randomly_selected_lines("data-raw/en.txt", .25 )
library(magrittr)
# Create file "data-raw/en.txt" (use 25% of the original lines)
sentences <- append(tw,bl) %>% append(.,ne) %>% write_randomly_selected_lines("data-raw/en.txt", .25 )
?rbinom
write_randomly_selected_lines <- function(text, filename, perc=.25) {
i <- rbinom(n = length(text),
size = 1,
perc = perc)
text <- text[i == 1]
con <- file(filename, open="wt")
writeLines(txt, con)
close(con)
}
# Create file "data-raw/en.txt" (use 25% of the original lines)
sentences <- append(tw,bl) %>% append(.,ne) %>% write_randomly_selected_lines("data-raw/en.txt", .25 )
write_randomly_selected_lines <- function(text, filename, perc=.25) {
i <- rbinom(n = length(text),
size = 1,
prob = perc)
text <- text[i == 1]
con <- file(filename, open="wt")
writeLines(txt, con)
close(con)
}
# Create file "data-raw/en.txt" (use 25% of the original lines)
sentences <- append(tw,bl) %>% append(.,ne) %>% write_randomly_selected_lines("data-raw/en.txt", .25 )
write_randomly_selected_lines <- function(text, filename, perc=.25) {
i <- rbinom(n = length(text),
size = 1,
prob = perc)
text <- text[i == 1]
con <- file(filename, open="wt")
writeLines(text, con)
close(con)
}
# Create file "data-raw/en.txt" (use 25% of the original lines)
sentences <- append(tw,bl) %>% append(.,ne) %>% write_randomly_selected_lines("data-raw/en.txt", .25 )
# Create file "data-raw/en.txt" (use 25% of the original lines)
append(tw,bl) %>% append(.,ne) %>% write_randomly_selected_lines("data-raw/en.txt", .25 )
tw <- readLines("data-raw/en_US.twitter.txt", warn = FALSE)
bl <-  readLines("data-raw/en_US.blogs.txt", warn = FALSE)
ne <- readLines("data-raw/en_US.news.txt", warn = FALSE)
# Create file "data-raw/en.txt" (use 25% of the original lines)
append(tw,bl) %>% append(.,ne) %>% write_randomly_selected_lines("data-raw/en.txt", .25 )
tw %>% write_randomly_selected_lines("data-raw/en_tw.txt", .5 )
bl %>% write_randomly_selected_lines("data-raw/en_bl.txt", .5 )
bl %>% write_randomly_selected_lines("data-raw/en_bl.txt", .4 )
np %>% write_randomly_selected_lines("data-raw/en_np.txt", .5 )
ne %>% write_randomly_selected_lines("data-raw/en_ne.txt", .5 )
ne <- readLines("data-raw/en_US.news.txt", warn = FALSE)
ne %>% write_randomly_selected_lines("data-raw/en_ne.txt", .5 )
ne <- readLines("data-raw/en_US.news.txt", warn = FALSE)
ne %>% write_randomly_selected_lines("data-raw/en_ne.txt", 1 )
library(devtools)
document()
library(magrittr)
library(enscnt)
## Prepare cleaned dataset `sentences`
ensentences <- readLines("data-raw/en_bl.txt", warn = FALSE) %>% clean_text(.)
usethis::use_data(en_bl, overwrite = TRUE)
en_bl <- readLines("data-raw/en_bl.txt", warn = FALSE) %>% clean_text(.)
usethis::use_data(en_bl, overwrite = TRUE)
library(magrittr)
library(enscnt)
## Prepare cleaned dataset `sentences`
en_ne <- readLines("data-raw/en_ne.txt", warn = FALSE) %>% clean_text(.)
usethis::use_data(en_ne, overwrite = TRUE)
library(magrittr)
library(enscnt)
## Prepare cleaned dataset `sentences`
en_tw <- readLines("data-raw/en_tw.txt", warn = FALSE) %>% clean_text(.)
usethis::use_data(en_tw, overwrite = TRUE)
write_randomly_selected_lines <- function(text, filename, perc = .25) {
i <- rbinom(n = length(text),
size = 1,
prob = perc)
text <- text[i == 1]
con <- file(filename, open = "wt")
writeLines(text, con)
close(con)
}
# Read source files.
tw <- readLines("data-raw/en_US.twitter.txt", warn = FALSE)
bl <-  readLines("data-raw/en_US.blogs.txt", warn = FALSE)
ne <- readLines("data-raw/en_US.news.txt", warn = FALSE)
# Create output files
append(tw, bl) %>% append(., ne) %>% write_randomly_selected_lines("data-raw/en.txt", .25)
library(magrittr)
library(enscnt)
## Prepare cleaned dataset `sentences`
ensentences <- readLines("data-raw/en.txt", warn = FALSE) %>% clean_text(.)
usethis::use_data(ensentences, overwrite = TRUE)
?enscnt
library(enscnt)
?enscnt
en_tw_sentences[1]
en_tw_sentences[2]
?ensentences
ensentences[1]
ensentences[2]
ensentences[3]
library(enscntr)
library(enscnt)
?enscnt
text <- en_ne_sentences
ngr <- ngrams_table(text)
ngr
ngrams_table <- function(text, ng = 2) {
i <- (word_count(text) >= ng)
text <- text[i == TRUE]
ngram_table <- text %>% ngram::ngram(ng) %>%
ngram::get.phrasetable()
ngram_table$ngrams <- trimws(ngram_table$ngrams)
ngram_table$ng <- ng
return(ngram_table)
}
ngr <- ngrams_table(text)
library(dplyr)
library(ngram)
ngrams_table <- function(text, ng = 2) {
i <- (word_count(text) >= ng)
text <- text[i == TRUE]
ngram_table <- text %>% ngram::ngram(ng) %>%
ngram::get.phrasetable()
ngram_table$ngrams <- trimws(ngram_table$ngrams)
ngram_table$ng <- ng
return(ngram_table)
}
ngr <- ngrams_table(text)
ngr
ngrams_table(en_ne_sentences[1:10])
ngrams_table(en_ne_sentences[1:10])
str(ngrams_table(en_ne_sentences[1:10]))
ngrams_table <- function(text, ng = 2) {
i <- (word_count(text) >= ng)
text <- text[i == TRUE]
ngram_table <- text %>% ngram::ngram(ng) %>%
ngram::get.phrasetable()
ngram_table$ngrams <- trimws(ngram_table$ngrams)
ngram_table$ng <- ng
return(ngram_table)
}
ngrams_tables <-
function(text,
ng = 3,
x = NULL) {
if (ng == 0) {
return(x)
}
else {
x <-
do.call("rbind",
list(ngrams_table(text, ng),
ngrams_tables(text, ng - 1, x)))
return(x)
}
}
load_all()
library(devtools)
load_all()
ngrams_tables(en_ne_sentences[1:10])
test <- ngrams_tables(en_ne_sentences[1:10])
tail(test)
sum(test$prop)
head(test)
document()
ngr <- ngrams_table(en_ne_sentences[1:10])
plot_ngrams(ngr)
plot_ngrams <- function(ngr,
title = "",
ng = 2,
m = 5) {
if (title == "") {
title <- paste0("Most Frequent ", toString(ng), "-gram")
}
barplot(
ngr$freq[1:m],
names.arg = ngr$ngrams[1:m],
main = title,
ylab = "Frequency"
)
}
plot_ngrams(ngr)
document()
document()
document()
document()
?barplot
document()
document()
library(enscnt)
library(enscnt)
?enscnt
library(enscnt)
pfx <- "this is a"
x <- en_bl_sentences
nGF <- ngrams_tables(x[1:100])
pMass         <- 1
# Probability mass to assign to ngrams (n=1..n)
pMassAssigned <- 0
# Total assigned probability mass
pMassN <- numeric() # Total probability mass assigned to ngrams of order n
word_count(pfx)
head(nGF)
n <- ng
nGF$prob <- 0
n
ng <- word_count(pfx) + 1
n <- ng
nGF$prob <- 0
head(nGF)
sub_df <- nGF %>% filter(ng == n)
library(magrittr)
sub_df <- nGF %>% filter(ng == n)
head(sub_df)
head(nGF)
j <- grep(paste0("^", pfx, " "), sub_df$ngram) #matching indices
str(sub_df)
sub_df <- nGF %>% filter(ng == n)
head(sub_df)
str(sub_df)
library(dplyr)
sub_df <- nGF %>% dplyr::filter(ng == n)
head(sub_df)
n
j <- grep(paste0("^", pfx, " "), sub_df$ngram) #matching indices
j
sub_df <- (sub_df[j,])
sub_df
sumfreq <- sum(sub_df$freq) #sum of frequencies
sumfreq
head(nGF)
?ngrams_tables
nGF <- ngrams_tables(x[1:100], ng=4)
head(dGF)
head(nGF)
nGF <- ngrams_tables(x[1:100], ng=4)
pfx <- "love spending"
nGF <- ngrams_tables(en_bl_sentences[1:100], ng=4)
head(nGF)
pfx <- "love spending"
pMass         <- 1
# Probability mass to assign to ngrams (n=1..n)
pMassAssigned <- 0
# Total assigned probability mass
pMassN <- numeric() # Total probability mass assigned to ngrams of order n
ng <- word_count(pfx) + 1
n <- ng
nGF$prob <- 0
n
sub_df <- nGF %>% dplyr::filter(ng == n)
head(sub_df)
pfx
j <- grep(paste0("^", pfx, " "), sub_df$ngram) # matching indices
j
j <- grep(paste0("^", pfx, " "), sub_df$ngrams) # matching indices
j
pfx
ng
head(sub_df)
j <- grep(paste0("^", pfx, " "), sub_df$ngrams) # matching indices
sub_df[20]
sub_df[20,]
sub_df <- (sub_df[j,]) # sub_df with matched text only
sub_df
sumfreq <- sum(sub_df$freq) #sum of frequencies
n
dplyr::filter(!id %in% sub_df$id)
filter(!id %in% sub_df$id)
nGF
head(nGF)
head(nGF)
nGF <- ngrams_tables(en_bl_sentences[1:100], ng=4)
pfx <- "love spending"
pMass         <- 1
# Probability mass to assign to ngrams (n=1..n)
pMassAssigned <- 0
# Total assigned probability mass
pMassN <- numeric() # Total probability mass assigned to ngrams of order n
ng <- word_count(pfx) + 1
n <- ng
nGF$prob <- 0
nGF %<>% mutate(id = row_number()) # Add row numbers
sub_df <- nGF %>% dplyr::filter(ng == n)
head(sub_df)
pMass         <- 1
# Probability mass to assign to ngrams (n=1..n)
pMassAssigned <- 0
# Total assigned probability mass
pMassN <- numeric() # Total probability mass assigned to ngrams of order n
ng <- word_count(pfx) + 1
n <- ng
nGF$prob <- 0
nGF %<>% mutate(id = row_number()) # Add row numbers
head(nGF)
pfx
sub_df <- nGF %>% dplyr::filter(ng == n)
head(sub_df)
j <- grep(paste0("^", pfx, " "), sub_df$ngrams) # matching indices
j
sub_df <- (sub_df[j,]) # sub_df with matched text only
sub_df
sumfreq <- sum(sub_df$freq) #sum of frequencies
nGF %<>% dplyr::filter(!id %in% sub_df$id) ## Remove records from nGF that will be updated
head(nGF)
sub_df$id
sub_df
nGF <- ngrams_tables(en_bl_sentences[1:100], ng=4)
nGF[3893,]
head(nGF)
names(nGF)
nGF <- ngrams_tables(en_bl_sentences[1:100], ng=4)
nGF %<>% mutate(id = row_number()) # Add row numbers
names(nGF)
sub_df <- nGF %>% dplyr::filter(ng == n)
j <- grep(paste0("^", pfx, " "), sub_df$ngrams) # matching indices
j
sub_df <- (sub_df[j,]) # sub_df with matched text only
sub_df
nGF
sumfreq <- sum(sub_df$freq) #sum of frequencies
sumfreq
sub_df$id
nGF %<>% dplyr::filter(id %in% sub_df$id) ## Remove records from nGF that will be updated
head(nGF)
nGF
nGF %<>% dplyr::filter(!(id %in% sub_df$id)) ## Remove records from nGF that will be updated
nGF
nGF <- ngrams_tables(en_bl_sentences[1:100], ng=4)
sub_df$id
(nGF$id %in% sub_df$id)
sub_df$id
nGF$id
nGF
nGF %<>% mutate(id = row_number()) # Add row numbers
nGF$id %in% sub_df$id
range(nGF$id %in% sub_df$id)
nGF %<>% dplyr::filter(!(nGF$id %in% sub_df$id))
head(nGF)
nGF <- ngrams_tables(en_bl_sentences[1:100], ng=4)
pMass         <- 1
# Probability mass to assign to ngrams (n=1..n)
pMassAssigned <- 0
# Total assigned probability mass
pMassN <- numeric() # Total probability mass assigned to ngrams of order n
ng <- word_count(pfx) + 1
n <- ng
nGF$prob <- 0
nGF %<>% mutate(id = row_number()) #
head(nGF)
sub_df <- nGF %>% dplyr::filter(ng == n)
head(sub_df)
j <- grep(paste0("^", pfx, " "), sub_df$ngrams) # matching indices
j
sub_df <- (sub_df[j,]) # sub_df with matched text only
sub_df
nGF[3893,]
nGF %<>% dplyr::anti_join(sub_df,by=id)
str(nGF)
head(nGF)
nGF <- ngrams_tables(en_bl_sentences[1:100], ng=4)
head(nGF)
nGF %<>% mutate(id = row_number()) # Add row numbers
head(nGF)
sub_df <- nGF %>% dplyr::filter(ng == n)
j <- grep(paste0("^", pfx, " "), sub_df$ngrams) # matching indices
sub_df <- (sub_df[j,]) # sub_df with matched text only
sub_df
head(nGF)
dplyr::anti_join(nGF,sub_df,by=id)
dplyr::anti_join(nGF,sub_df,by="id")
nGF %<>% dplyr::anti_join(sub_df,by="id")
nGF[3893,]
sub_df %<>% dplyr::mutate(prob = pMass * (freq - discnt) / sumfreq) # calculate probability
discnt <- 0.5
sub_df %<>% dplyr::mutate(prob = pMass * (freq - discnt) / sumfreq) # calculate probability
sub_df
pMassN <- append(pMassN,sum(sub_df$prob[]))
pMassAssigned %<>% sum(., tail(pMassN,1))
pMass <- 1 - pMassAssigned
nGF <-
do.call(rbind, list(nGF, sub_df)) ## Add updated records to nGF
str(nGF)
str(sub_df)
nGF$prob <- 0
nGF <-
do.call(rbind, list(nGF, sub_df)) ## Ad
RemoveFirstWord <- function(txt) {
txt %<>% trimws(.)
if (stringi::stri_count(txt, regex = "\\p{L}+") > 1) {
#Only one word
i <- unlist(gregexpr(pattern = ' ', txt))[1]
substr(txt, i + 1, nchar(txt))
} else
return("")
}
pfx
pfx <- RemoveFirstWord(pfx)
pfx
setProbsOfnGrams <- function(pfx, nGF, discnt = 0.5) {
pMass         <- 1
# Probability mass to assign to ngrams (n=1..n)
pMassAssigned <- 0
# Total assigned probability mass
pMassN <- numeric() # Total probability mass assigned to ngrams of order n
ng <- word_count(pfx) + 1
n <- ng
nGF$prob <- 0
nGF %<>% mutate(id = row_number()) # Add row numbers
while (n >= 1) { # backing off through progressively shorter history models
sub_df <- nGF %>% dplyr::filter(ng == n)
if (n > 1) {
j <- grep(paste0("^", pfx, " "), sub_df$ngrams) # matching indices
sub_df <- (sub_df[j,]) # sub_df with matched text only
}
sumfreq <- sum(sub_df$freq) #sum of frequencies
if (sumfreq > 0) { #one or more matches
if (n == 1) {
discnt <- 0
}
nGF %<>% dplyr::anti_join(sub_df,by="id") # Remove records that will be updated
sub_df %<>% dplyr::mutate(prob = pMass * (freq - discnt) / sumfreq) # calculate probability
pMassN <- append(pMassN,sum(sub_df$prob[]))
pMassAssigned %<>% sum(., tail(pMassN,1))
pMass <- 1 - pMassAssigned
nGF <-
do.call(rbind, list(nGF, sub_df)) ## Add updated records to nGF
}
pfx <- RemoveFirstWord(pfx)
n <- n - 1
}
nGF %<>% arrange(., desc(prob))
return(list(nGF=nGF,pMassN=data.frame(n=seq(length(pMassN),by=-1),pMass=pMassN)))
}
test <- setProbsOfnGrams(pfx, nGF)
test
sum(test$pMassN)
sum(test$
test$
test$nGF
sum(test$nGF$prob)
test <- setProbsOfnGrams(pfx, nGF, 0.1)
test$nGF
test <- setProbsOfnGrams(pfx, nGF, 0.75)
test$nGF
setProbsOfnGrams <- function(pfx, nGF, discnt = 0.5) {
pMass         <- 1
# Probability mass to assign to ngrams (n=1..n)
pMassAssigned <- 0
# Total assigned probability mass
pMassN <- numeric() # Total probability mass assigned to ngrams of order n
ng <- word_count(pfx) + 1
n <- ng
nGF$prob <- 0
nGF %<>% mutate(id = row_number()) # Add row numbers
while (n >= 1) { # backing off through progressively shorter history models
sub_df <- nGF %>% dplyr::filter(ng == n)
if (n > 1) {
j <- grep(paste0("^", pfx, " "), sub_df$ngrams) # matching indices
sub_df <- (sub_df[j,]) # sub_df with matched text only
}
sumfreq <- sum(sub_df$freq) #sum of frequencies
if (sumfreq > 0) { #one or more matches
if (n == 1) {
discnt <- 0
}
nGF %<>% dplyr::anti_join(sub_df,by="id") # Remove records that will be updated
sub_df %<>% dplyr::mutate(prob = pMass * (freq - discnt) / sumfreq) # calculate probability
pMassN <- append(pMassN,sum(sub_df$prob[]))
pMassAssigned %<>% sum(., tail(pMassN,1))
pMass <- 1 - pMassAssigned
nGF <-
do.call(rbind, list(nGF, sub_df)) ## Add updated records to nGF
}
pfx <- RemoveFirstWord(pfx)
n <- n - 1
}
nGF %<>% arrange(., desc(prob))
return(nGF)
}
test <- setProbsOfnGrams(pfx, nGF, 0.1)
test
test <- setProbsOfnGrams(pfx, nGF, 0.75)
head(test)
test <- setProbsOfnGrams(pfx, nGF, 0.9)
head(test)
test <- setProbsOfnGrams(pfx, nGF, 0.95)
head(test)
