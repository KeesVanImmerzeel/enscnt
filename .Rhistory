clean_text <- function(text) {
text <- text %>%
replace_word_elongation() %>% # Replace elongation words
gsub("[^A-Za-z ]", "", .) %>% # Remove all characters that are not letters or space.
gsub("\\s+", " ", .) %>% # Remove multiple white spaces
trimws() %>% # Trim trailing and leading white space
tolower() # Convert to lowercase
return(text)
}
DATASET %>% head(.) %>% clean_text(.)
DATASET %>% tail(.,20) %>% clean_text(.)
?rbinom
i <- rbinom(n = length(DATASET),
size = 1,
prob = .5)
DATASET <- DATASET[i == 1]
usethis::use_data(DATASET, overwrite = TRUE)
scentences
load_all()
?sentences
load_all()
?enscnt
?sentences
load_all()
?sentences
library(devtools)
load_all()
?sentences
??sentences
?enscnt
sentences
library(magrittr)
library(enscnt)
## Prepare `sentences`
tw <- readLines("data-raw/en_US.twitter.txt", warn = FALSE)
bl <-  readLines("data-raw/en_US.blogs.txt", warn = FALSE)
ne <- readLines("data-raw/en_US.news.txt", warn = FALSE)
sentences <- append(tw,bl) %>% append(.,ne) %>% clean_text(.)
# Select 50% of the lines
i <- rbinom(n = length(sentences),
size = 1,
prob = .5)
sentences <- sentences[i == 1]
usethis::use_data(sentences, overwrite = TRUE)
load_all()
?sentences
head(sentences)
df <- data_frame(sentences) %>%
unnest_tokens(word, text) %>%
##anti_join(stop_words) %>%
count(word, sort = TRUE) %>%
mutate(id = row_number()) ## id = the number of frequently used words
library(tibble)
df <- data_frame(sentences) %>%
unnest_tokens(word, text) %>%
##anti_join(stop_words) %>%
count(word, sort = TRUE) %>%
mutate(id = row_number()) ## id = the number of frequently used words
library(tidytext)
install.packages("tidytext")
df <- data_frame(sentences) %>%
unnest_tokens(word, text) %>%
##anti_join(stop_words) %>%
count(word, sort = TRUE) %>%
mutate(id = row_number()) ## id = the number of frequently used words
library(tidytext)
df <- data_frame(sentences) %>%
unnest_tokens(word, text) %>%
##anti_join(stop_words) %>%
count(word, sort = TRUE) %>%
mutate(id = row_number()) ## id = the number of frequently used words
df <- data_frame(sentences[1]) %>%
unnest_tokens(word, text) %>%
##anti_join(stop_words) %>%
count(word, sort = TRUE) %>%
mutate(id = row_number()) ## id = the number of frequently used words
df <- data_frame(sentences[1])
tw <- readLines("data-raw/en_US.twitter.txt", warn = FALSE)
bl <-  readLines("data-raw/en_US.blogs.txt", warn = FALSE)
?unnest_tokens
ne <- readLines("data-raw/en_US.news.txt", warn = FALSE)
sentences <- append(tw,bl) %>% append(.,ne) %>% clean_text(.)
df <- data_frame(sentences) %>%
unnest_tokens(word, text) %>%
##anti_join(stop_words) %>%
count(word, sort = TRUE)
df <- data_frame(sentences[1]) %>%
unnest_tokens(word, text) %>%
##anti_join(stop_words) %>%
count(word, sort = TRUE)
df <- data_frame(sentences[1]) %>%
unnest_tokens(word, text)
df <- data_frame(sentences[1])
df
head(df)
df[2]
library(magrittr)
library(enscnt)
library(tibble)
library(tidytext)
## Prepare `sentences`
tw <- readLines("data-raw/en_US.twitter.txt", warn = FALSE)
bl <-  readLines("data-raw/en_US.blogs.txt", warn = FALSE)
ne <- readLines("data-raw/en_US.news.txt", warn = FALSE)
sentences <- append(tw,bl) %>% append(.,ne)
i <- rbinom(n = length(sentences),
size = 1,
prob = .5)
sentences <- sentences[i == 1]
?writeLines
con <- file("data-raw/en.txt", open="wt")
writeLines(sentences, con)
close(con)
tw <- readLines("data-raw/en_US.twitter.txt", warn = FALSE)
bl <-  readLines("data-raw/en_US.blogs.txt", warn = FALSE)
ne <- readLines("data-raw/en_US.news.txt", warn = FALSE)
sentences <- append(tw,bl) %>% append(.,ne)
i <- rbinom(n = length(sentences),
size = 1,
prob = .25)
sentences <- sentences[i == 1]
con <- file("data-raw/en.txt", open="wt")
writeLines(sentences, con)
close(con)
library(magrittr)
# Prepare a dataset 'data-raw/en.txt' of Englisch sentences drawn from twitter, blogs and newspapers.
# Data is used from the following source
# But actually not included in the package since it is too large.
# https://d396qusza40orc.cloudfront.net/dsscapstone/dataset/Coursera-SwiftKey.zip
# So, before running this code, make sure the following files are present
# in the folder data-raw.
tw <- readLines("data-raw/en_US.twitter.txt", warn = FALSE)
bl <-  readLines("data-raw/en_US.blogs.txt", warn = FALSE)
ne <- readLines("data-raw/en_US.news.txt", warn = FALSE)
sentences <- append(tw,bl) %>% append(.,ne)
# Select 25% of the lines and write the selecte lines to 'data-raw/en.txt'.
i <- rbinom(n = length(sentences),
size = 1,
prob = .25)
sentences <- sentences[i == 1]
con <- file("data-raw/en.txt", open="wt")
writeLines(sentences, con)
close(con)
library(magrittr)
library(enscnt)
library(tibble)
library(tidytext)
## Prepare cleaned dataset `sentences`
sentences <- readLines("data-raw/en.txt", warn = FALSE)
## Prepare cleaned dataset `sentences`
sentences <- readLines("data-raw/en.txt", warn = FALSE) %>% clean_text(.)
library(magrittr)
library(enscnt)
## Prepare cleaned dataset `sentences`
sentences <- readLines("data-raw/en.txt", warn = FALSE) %>% clean_text(.)
usethis::use_data(sentences, overwrite = TRUE)
library(devtools)
document()
load_all()
?sentences
library(devtools)
document()
?ensentences
?ensentences
options(devtools.desc.author=person(given = "Kees",
+                                     family = "van Immerzeel",
+                                     role = c("aut", "cre"),
+                                     email = "c.h.van.immerzeel@gmail.com",
+                                     comment = c(ORCID = "https://orcid.org/0000-0003-0926-3248")))
options(devtools.desc.author=person(given = "Kees", family = "van Immerzeel", role = c("aut", "cre"), email = "c.h.van.immerzeel@gmail.com", comment = c(ORCID = "https://orcid.org/0000-0003-0926-3248")))
options(devtools.desc.license="Artistic-2.0")
document()
?install.packages()
?install.packages("KeesVanImmerzeel/enscnt")
install.packages("KeesVanImmerzeel/enscnt")
install.packages("https://github.com/KeesVanImmerzeel/enscnt")
devtools::install_github("KeesVanImmerzeel/enscnt")
libPath()
devtools::install_github("KeesVanImmerzeel/enscnt")
library(devtools)
document()
library(magrittr)
library(enscnt)
## Prepare cleaned dataset `sentences`
ensentences <- readLines("data-raw/en.txt", warn = FALSE) %>% clean_text(.)
usethis::use_data(ensentences, overwrite = TRUE)
load_all()
devtools::install_github("KeesVanImmerzeel/enscnt")
library(enscnt)
?enscnt
clean_text("8907dsf")
?ensentences
ensenteces[1]
ensentences[1]
?enscnt
?ensentences
load_all()
library(devtools)
load_all
load_all()
?clean_text
?ensentences
library(devtools)
document()
load_all()
?enscnt
?ensentence
?ensentences
document()
load_all
load_all()
?ensentences
document()
load_all()
?ensentences
document()
load_all()
?ensentences
library("enscnt")
?ensentences
?enscnt
enscnt[1]
x <- ensentences[1:3]
paste(x,collapse="")
x[1]
x[2]
paste(x,collapse=" ")
setwd("~/kees/Coursera/DataScience/Capstone2")
install.packages("ngram")
library(enscnt)
x <- ensentences
sampleNlines <- function ( text, aFraction, maxNrLines ){
nrLines <-length(text)
text <-
text[sample(1:nrLines,
min(aFraction * nrLines, maxNrLines),
replace = F)]
return(text)
}
sampleNlines(text=x, aFraction = 0.01, maxNrLines = 100)
sampleNlines(text=x, aFraction = 0.01, maxNrLines = 10)
xs <- sampleNlines(text=x, aFraction = 0.01, maxNrLines = 10)
str(xs)
xs[1]
xs[2]
ngram(xs)
library (ngram)
ngram(xs)
str(ngram(xs))
ngram(xs) %>% get.phrasetable ()
library (devtools)
library (ngram)
library(magrittr)
library(stringi)
ngram(xs) %>% get.phrasetable ()
?ngram
ngram(xs, 1) %>% get.phrasetable ()
generateTableOfngrams <- function(text, n) {
txt <- text %>%
sampleNlines(aFraction = 0.01, maxNrLines = 5000)  %>%
ngram(n) %>%
get.phrasetable ()
return(text)
}
generateTableOfngrams(xs, n=1)
xs
generateTableOfngrams <- function(text, n) {
txt <- text %>%
ngram(n) %>%
get.phrasetable ()
return(text)
}
generateTableOfngrams(xs, n=1)
ngram1 <- generateTableOfngrams(xs, n=1)
ngram1
ngram(xs)
ngram(xs) %>% get.phrasetable()
generateTableOfngrams <- function(text, n) {
txt <- text %>%
ngram(n) %>%
get.phrasetable()
return(txt)
}
ngram1 <- generateTableOfngrams(xs, n=1)
ngram1
x <- ensentences
xs <- sampleNlines(text=x, aFraction = 0.01, maxNrLines = 1000)
x[1000]
?sample
sampleNlines <- function ( text, aFraction ){
nrLines <- length(text)
i <- rbinom(n = nrLines,
size = 1,
prob = aFraction)
return(sentences[i == 1])
}
xs <- sampleNlines(text=x, aFraction = 0.01)
xs
length(xs)
generateTableOfngrams <- function(text, n) {
txt <- text %>%
ngram(n) %>%
get.phrasetable()
return(txt)
}
ngram1 <- generateTableOfngrams(xs, n=1)
xs <- sampleNlines(text=x, aFraction = 0.01)
xs
xs %>% ngram(1)
xs
xs %>% ngram(1)
xs <- xs[1:10]
xs %>% ngram(1)
xs <- sampleNlines(text=x, aFraction = 0.01)
xs <- stri_remove_empty(xs)
ngram1 <- generateTableOfngrams(xs, n=1)
ngram1
?trimws()
?tolower()
?stri_remove_empty
library(devtools)
use_package(stringi)
use_package("stringi")
clean_text <- function(x) {
text <- x %>%
textclean::replace_word_elongation() %>% # Replace elongation words
gsub("[^A-Za-z ]", "", .) %>% # Remove all characters that are not letters or space.
gsub("\\s+", " ", .) %>% # Remove multiple white spaces
trimws() %>% # Trim trailing and leading white space
tolower() %>%  # Convert to lowercase
stri_remove_empty()
return(text)
}
library (devtools)
library (ngram)
library(magrittr)
library(stringi)
library(enscnt)
setwd("~/kees/Coursera/DataScience/Capstone2")
sampleNlines <- function ( text, aFraction ){
nrLines <- length(text)
i <- rbinom(n = nrLines,
size = 1,
prob = aFraction)
return(sentences[i == 1])
}
generateTableOfngrams <- function(text, n) {
txt <- text %>%
ngram(n) %>%
get.phrasetable()
return(txt)
}
x <- ensentences
xs <- sampleNlines(text=x, aFraction = 0.01)
ngram1 <- generateTableOfngrams(xs, n=1)
library(devtools)
devtools::install_github("KeesVanImmerzeel/ensnct")
devtools::install_github("KeesVanImmerzeel/enscnt")
library(enscnt)
x <- ensentences
xs <- sampleNlines(text=x, aFraction = 0.01)
sampleNlines <- function ( text, aFraction ){
nrLines <- length(text)
i <- rbinom(n = nrLines,
size = 1,
prob = aFraction)
return(sentences[i == 1])
}
generateTableOfngrams <- function(text, n) {
txt <- text %>%
ngram(n) %>%
get.phrasetable()
return(txt)
}
xs <- sampleNlines(text=x, aFraction = 0.01)
ngram1 <- generateTableOfngrams(xs, n=1)
library (devtools)
library (ngram)
library(magrittr)
library(stringi)
library(enscnt)
ngram1 <- generateTableOfngrams(xs, n=1)
library(enscnt)
?enscnt
clean_text()
??clean_text()
devtools::install_github("KeesVanImmerzeel/ensnct")
devtools::install_github("KeesVanImmerzeel/enscnt")
library(enscnt)
xs <- sampleNlines(text=x, aFraction = 0.01)
library (devtools)
library (ngram)
library(magrittr)
library(stringi)
library(enscnt)
setwd("~/kees/Coursera/DataScience/Capstone2")
sampleNlines <- function ( text, aFraction ){
nrLines <- length(text)
i <- rbinom(n = nrLines,
size = 1,
prob = aFraction)
return(sentences[i == 1])
}
generateTableOfngrams <- function(text, n) {
txt <- text %>%
ngram(n) %>%
get.phrasetable()
return(txt)
}
xs <- sampleNlines(text=x, aFraction = 0.01)
x <- ensentences
xs <- sampleNlines(text=x, aFraction = 0.01)
ngram1 <- generateTableOfngrams(xs, n=1)
methods(clean_text)
clean_text
?stri_remove_empty
i <- which(xs=="")
i
xs[6609]
clean_text <- function(x) {
text <- x %>%
textclean::replace_word_elongation() %>% # Replace elongation words
gsub("[^A-Za-z ]", "", .) %>% # Remove all characters that are not letters or space.
gsub("\\s+", " ", .) %>% # Remove multiple white spaces
trimws() %>% # Trim trailing and leading white space
tolower() %>%  # Convert to lowercase
stringi::stri_remove_empty() # Remove empty lines
return(text)
}
library(magrittr)
library(enscnt)
## Prepare cleaned dataset `sentences`
ensentences <- readLines("data-raw/en.txt", warn = FALSE) %>% clean_text(.)
which(ensentences=="")
usethis::use_data(ensentences, overwrite = TRUE)
devtools::install_github("KeesVanImmerzeel/enscnt")
library(devtools)
devtools::install_github("KeesVanImmerzeel/enscnt")
libPaths()
.libPaths
.libPaths()
library(devtools)
library(devtools)
devtools::install_github("KeesVanImmerzeel/enscnt")
devtools::install_github("KeesVanImmerzeel/enscnt",force=TRUE)
library(stringi)
?stri_remove_empty()
#' Transform text with non-text characters to 'clean' text
#'
#' Remove non-text characters. Numbers are also removed.
#'
#' @param x (character) Text to clean.
#'
#' @return (character) Cleaned text.
#'
#' @importFrom textclean replace_word_elongation
#' @importFrom magrittr %>%
#' @importFrom stringi stri_remove_empty
#'
#' @export
clean_text <- function(x) {
text <- x %>%
textclean::replace_word_elongation() %>% # Replace elongation words
gsub("[^A-Za-z ]", "", .) %>% # Remove all characters that are not letters or space.
gsub("\\s+", " ", .) %>% # Remove multiple white spaces
trimws() %>% # Trim trailing and leading white space
tolower() %>%  # Convert to lowercase
stringi::stri_remove_empty_na() # Remove empty lines
return(text)
}
library(magrittr)
library(enscnt)
clean_text <- function(x) {
text <- x %>%
textclean::replace_word_elongation() %>% # Replace elongation words
gsub("[^A-Za-z ]", "", .) %>% # Remove all characters that are not letters or space.
gsub("\\s+", " ", .) %>% # Remove multiple white spaces
trimws() %>% # Trim trailing and leading white space
tolower() %>%  # Convert to lowercase
stringi::stri_remove_empty_na() # Remove empty lines
return(text)
}
## Prepare cleaned dataset `sentences`
ensentences <- readLines("data-raw/en.txt", warn = FALSE) %>% clean_text(.)
i <- is.na(ensentences)
range(i)
i <- ensentences==""
range(i)
usethis::use_data(ensentences, overwrite = TRUE)
.libPaths
.libPaths()
library(devtools)
document()
load_all()
?sampleNlines()
?word_count()
load_all()
library(enscnt)
?word_count()
?generateTableOfngrams
?enscnt
library(devtools)
devtools::load_all()
?enscnt
library(devtools)
document()
document()
document()
load_all()
x <- ensentences
xs <- sampleNlines(x, 0.01)
ngram2 <- generateTableOfngrams(xs, n=2)
